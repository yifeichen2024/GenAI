{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.48.3\n",
    "!pip install datasets==3.2.0\n",
    "!pip install torch==2.5.1\n",
    "!pip install numpy==1.25.0\n",
    "!pip install pandas==2.2.2\n",
    "!pip install peft==0.10.0\n",
    "!pip install trl==0.14.0\n",
    "!pip install huggingface-hub==0.26.1\n",
    "!pip install google-generativeai==0.8.4\n",
    "!pip install tqdm==4.67.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import submission as submission\n",
    "import dpo\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Generate Completions\n",
    "\n",
    "A core component in RLHF (and generative AI) is the quality of data used to train the model. Generating data goes against conventional statistical practices, but has turned out to be a powerful tool for training generative AI models. \n",
    "\n",
    "In this assignment, you will generate completions for a given IMDB movie review. You are given a dataset of over 500 movie reviews, but truncated to the first four words. From these four words, your goal is to use DPO to generate positive sentiment completions based on the first four words.\n",
    "\n",
    "Your task for Part 1 is as follows:\n",
    "\n",
    "0. Download the `pretrained.zip` file from the assignment files and unzip it. It should produce a filed called `sft_models`. Make sure it is in your working directory.\n",
    "1. Fill out the `huggingface_key()` and `gemini_api_key()` functions in the `submission.py` file to be able to access our API calls \n",
    "2. Fill out the `pair_generator()` function in the `submission.py` file. Your goal is to prompt Gemini to generate 1) a positive sentiment completion and 2) a negative sentiment completion for each of the first four words of a given review. Be sure to instruct the model to keep the reviews short, max 1-2 sentences long.\n",
    "3. Run the cells below to generate the completions. It is up to you to determine how many completions to generate. Generally, more data is better. \n",
    "4. Once the completions are generated, it will be saved to a csv file called `imdb_completions.csv`. Gemini will most likely return a completion that includes the first 4 words of the input text. We need to remove the first 4 words of the completion so that it is in the correct format. A function has been provided to you to do this in `submission.py` called `fix_completions()`. Run that function to fix the completions, which will save the fixed completions to a csv file called `imdb_completions_edited.csv`.\n",
    "\n",
    "If you have successfully completed Part 1, you should now have 2 csv files in your working directory: `imdb_completions.csv` and `imdb_completions_edited.csv` populated with an `Input_Text`, `Accepted_Completion`, and `Rejected_Completion` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify you key is set\n",
    "assert submission.huggingface_key() != \"\", \"You need to set your huggingface key.\"\n",
    "assert submission.gemini_api_key() != \"\", \"You need to set your gemini api key.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 # number of completions to generate. You should change this to another number. Generally, more data is better. The highest you can set is 512.\n",
    "df = pd.read_csv(\"imdb_kernels.csv\")\n",
    "df = df.iloc[:n]\n",
    "submission.dataset_generator(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.fix_completions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Train DPO\n",
    "Now that you have the generated completions, you can train a DPO model.\n",
    "\n",
    "Your task for Part 2 is as follows:\n",
    "\n",
    "1. Fill out the `MyDPOConfig` class in the `submission.py` file. There are 2 parameters you can play with: `learning_rate`, and `beta`.\n",
    "\n",
    "2. After filling out these values, run the cell below to train the DPO model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = submission.MyDPOConfig()\n",
    "original_model, tokenizer = dpo.load_model(config)\n",
    "trained_model = dpo.train_dpo(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3: Evaluate DPO\n",
    "\n",
    "Your deliverable is the trained DPO model. It should have been trained in the cell above and the model should be in a variable called `trained_model`.\n",
    "\n",
    "You will be scored on how positive your generated completions are.\n",
    "\n",
    "To get a sense of how good your model is, you can run the cell below. It will generate completions for the first 20 reviews in the dataset and print the completions.\n",
    "\n",
    "We will be scoring you on a holdout set of 100 reviews, so the scores you see below may not be indicative of your final score. It is up to you to determine how thoroughly you want to evaluate your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell pushes your trained model to the hub which will be graded.\n",
    "trained_model.push_to_hub(submission.hub_model_name(), token=submission.huggingface_key())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell generates completions using your DPO trained model and the based model from pretrained.zip\n",
    "dpo_completions = []\n",
    "original_model_completions = []\n",
    "for k, row in df.iloc[:20].iterrows():  \n",
    "    prompt = row['Input_Text']\n",
    "    dpo_completions.append(dpo.run_inference(config, trained_model, prompt))\n",
    "    original_model_completions.append(dpo.run_inference(config, original_model, prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell prints the completions\n",
    "completions = {'DPO': dpo_completions[:2], 'Original Model': original_model_completions[:2]}\n",
    "pd.set_option('display.max_colwidth', None)  # Allow full string display\n",
    "pd.DataFrame(completions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell classifies the completions as positive or negative and gives the percentage of positive completions\n",
    "classes = submission.batch_classification(dpo_completions)\n",
    "print(f\"DPO Positive Completion Rate: {sum([c == 'POSITIVE' for c in classes]) / len(classes)}\")\n",
    "\n",
    "classes = submission.batch_classification(original_model_completions)\n",
    "print(f\"Original Model Positive Completion Rate: {sum([c == 'POSITIVE' for c in classes]) / len(classes)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Rubric:\n",
    "\n",
    "Your grade is based on how positive your DPO generated completions are.\n",
    "- Positive completion rate >= 0.95: Score: 1.0\n",
    "- Positive completion rate >= 0.85: Score: 0.9\n",
    "- Positive completion rate >= 0.7: Score: 0.5\n",
    "- Positive completion rate >= 0.6: Score: 0.4\n",
    "- Positive completion rate >= 0.5: Score: 0.2\n",
    "- Positive completion rate < 0.5: Score: 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
